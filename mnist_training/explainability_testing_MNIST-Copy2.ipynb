{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7b10c3-cc5f-4f28-86dd-2b075ccf4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models as tvmodels\n",
    "from torchsummary import summary\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "\n",
    "import torchvision.models as torchvisionmodels\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "import itertools\n",
    "import more_itertools\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from captum.attr import LayerGradCam\n",
    "from captum.attr import visualization\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from dask_image.imread import imread\n",
    "from dask_image import ndfilters, ndmorph, ndmeasure\n",
    "import matplotlib.pyplot as plt\n",
    "from dask_image import ndmeasure\n",
    "\n",
    "from operator import itemgetter\n",
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d28e9f04-b41c-4497-b72d-72955325ac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and data loaded\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from trainer import *\n",
    "\n",
    "allowed_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "labels_map = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9'\n",
    "}\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# model = MNIST_model(len(allowed_classes))\n",
    "# checkpoint = torch.load('resnet_models/resnet18.pt')\n",
    "# model.load_state_dict(checkpoint)\n",
    "\n",
    "model_dict = torch.load('resnet_models/grad_cam_model.pt')\n",
    "model = gradcam_model()\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_data, valid_data, test_data = create_dataloaders_MNIST(batch_size)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"Model and data loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc9b65b-403c-4762-a4a3-d68efd8d0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_img_transform = transforms.Normalize((0.1307,), (0.3081,))\n",
    "# This is to reverse the normalization done to the images that centered them around imagenet mean and std\n",
    "# The invTrans should be used on images before saving them.\n",
    "invTrans = transforms.Normalize((1/0.1307,), (1/0.3081,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0334fe86-7945-4b86-ad21-9599388b54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f978c487760>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#images, labels = next(itertools.islice(testloader, 48, None))\n",
    "images, labels = next(itertools.islice(test_data, 0, None))\n",
    "\n",
    "print(labels)\n",
    "outputs = model(images.to(device))\n",
    "_, predicted = outputs.max(1)\n",
    "print(predicted)\n",
    "pred_val = predicted.item()\n",
    "plt.imshow( images.detach().cpu().squeeze(), cmap='gray' )\n",
    "\n",
    "# Good sevens: 5, 8, 9, 13, 16, 17, 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84dcbd51-01e7-4670-9290-0a6d4f80e540",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "from pytorch_grad_cam import XGradCAM, GradCAM, FullGrad, GradCAMPlusPlus, ScoreCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from skimage.segmentation import slic, felzenszwalb, quickshift, watershed\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43085c17-7287-4bd2-9a32-43fb2384b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grayscale_grad_cam(image, SMU_class_index):\n",
    "    input_tensor = image.to(device)\n",
    "    targets = [ClassifierOutputTarget(SMU_class_index)]\n",
    "    #target_layers = [model.layer4[-1]]\n",
    "    target_layers = [model.layer2]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    \n",
    "    return(grayscale_cam)\n",
    "\n",
    "def segmentation_info(image, num_segments, compactness):\n",
    "    img_np = image.detach().cpu().squeeze().numpy()\n",
    "    segments_slic = slic(img_np, n_segments = num_segments, compactness=compactness,\n",
    "                     start_label=1)\n",
    "    num_segments = len(np.unique(segments_slic))\n",
    "    list_unique_regions = np.unique(segments_slic)\n",
    "    segment_pixel_num_list = []\n",
    "    total_pixels = 0\n",
    "    for i in (list_unique_regions):\n",
    "        num_pixels = np.count_nonzero(segments_slic == i)\n",
    "        segment_pixel_num_list.append(num_pixels)\n",
    "        total_pixels += num_pixels\n",
    "    \n",
    "    \n",
    "    information_for_each_segment = []\n",
    "    for i in (list_unique_regions):\n",
    "        image_list = []\n",
    "        image_list.append(i)\n",
    "        image_list.append(segment_pixel_num_list[i-1])\n",
    "        image_list.append(total_pixels)\n",
    "        information_for_each_segment.append(image_list)\n",
    "\n",
    "    return(information_for_each_segment, segments_slic, num_segments)\n",
    "\n",
    "\n",
    "# I want to get the average attribution score for each segment\n",
    "def cam_processor_for_segments(grayscale_cam_output, segments_slic):\n",
    "    \n",
    "    \n",
    "    \n",
    "    list_unique_regions = np.unique(segments_slic)\n",
    "    region_attr_score = []\n",
    "    final_region_attr_score = []\n",
    "    num_pixels_in_region_list = []\n",
    "    \n",
    "    for i in (list_unique_regions):\n",
    "        row_counter = 0\n",
    "        column_counter = 0\n",
    "        region_attr_score = []\n",
    "        num_pixels_in_region = 0\n",
    "        for row in grayscale_cam_output:\n",
    "            for cell in row:\n",
    "                current_score = grayscale_cam_output[row_counter, column_counter]\n",
    "                current_region = segments_slic[row_counter, column_counter]\n",
    "                if current_region == i:\n",
    "                    region_attr_score.append(current_score)\n",
    "                    num_pixels_in_region += 1\n",
    "                column_counter +=1\n",
    "            row_counter += 1\n",
    "            column_counter = 0\n",
    "        avg_score = np.mean(region_attr_score)\n",
    "        final_region_attr_score.append(avg_score)\n",
    "        num_pixels_in_region_list.append(num_pixels_in_region)\n",
    "    \n",
    "    unique_region_info = []\n",
    "    for i in (list_unique_regions):\n",
    "        image_list = []\n",
    "        image_list.append(i)\n",
    "        image_list.append(final_region_attr_score[i-1])\n",
    "        image_list.append(num_pixels_in_region_list[i-1])\n",
    "        image_list.append(np.sum(num_pixels_in_region_list))\n",
    "        unique_region_info.append(image_list)\n",
    "    \n",
    "    return(unique_region_info)\n",
    "\n",
    "\n",
    "def get_feature_masks(image, attributions, segments_slic):\n",
    "    segments_slic_1 = segments_slic\n",
    "    features = []\n",
    "    for i in attributions:\n",
    "        feature = np.where(i==segments_slic_1, 1, 0)\n",
    "        features.append(feature)\n",
    "        \n",
    "    return(features)\n",
    "\n",
    "\n",
    "def attribution_ranker(cam_processor_for_segments_output, num_top_attr):\n",
    "    ranked_images = sorted(cam_processor_for_segments_output, key=itemgetter(1), reverse=True)\n",
    "    top_ranked_features = []\n",
    "    for i in range(num_top_attr):\n",
    "        top_ranked_features.append(ranked_images[i][0])\n",
    "        \n",
    "    return top_ranked_features\n",
    "\n",
    "\n",
    "\n",
    "def image_rankings(get_image_versions):\n",
    "    #for idx in iterative_Grad_CAM_counterfactual_masking_output\n",
    "    ranked_images = sorted(get_image_versions, key=itemgetter(3))\n",
    "    \n",
    "    return ranked_images\n",
    "\n",
    "def blur_image_from_attribution(image, attribution_map):\n",
    "    # attribution map is the attributions after being passed through the attribution processor\n",
    "    # image is a tensor\n",
    "    # will output the blurred image based on the attribution map\n",
    "    \n",
    "    \n",
    "    #average_img = image.squeeze().cpu().permute(1, 2, 0).numpy()\n",
    "    #avg = np.average(average_img)\n",
    "    #blurred_img = cv2.GaussianBlur(image.squeeze().cpu().permute(1, 2, 0).numpy(), (181, 181), 0)\n",
    "    avg = np.float32(-0.4242)\n",
    "    #avg_img = np.where(average_img > 9999, average_img, avg)\n",
    "    \n",
    "    #attribution_map = attribution_map.detach().squeeze().cpu().numpy()\n",
    "    \n",
    "    mask = [attribution_map]\n",
    "    mask = np.array(mask).squeeze()\n",
    "    #mask = mask.transpose(1,2,0)\n",
    "    #print(mask.shape)\n",
    "    #print(image.squeeze().cpu().numpy().shape)\n",
    "    \n",
    "    \n",
    "    out = np.where(mask==np.array([0]), image.squeeze().cpu().numpy(), avg)\n",
    "    #out = np.where(mask==np.array([0, 0, 0]), image.squeeze().cpu().permute(1, 2, 0).numpy(), blurred_img)\n",
    "    \n",
    "    out = torch.tensor(out)\n",
    "    out = out\n",
    "    out = out.unsqueeze(0)\n",
    "    out = out.unsqueeze(0)\n",
    "    #print(out.shape)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe8a8e-6985-4874-beae-7986815658f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_info_slic(image, num_segments, compactness):\n",
    "    img_np = image.detach().cpu().squeeze().numpy()\n",
    "    segments_slic = slic(img_np, n_segments = num_segments, compactness=compactness,\n",
    "                     start_label=1)\n",
    "    num_segments = len(np.unique(segments_slic))\n",
    "    list_unique_regions = np.unique(segments_slic)\n",
    "    segment_pixel_num_list = []\n",
    "    total_pixels = 0\n",
    "    for i in (list_unique_regions):\n",
    "        num_pixels = np.count_nonzero(segments_slic == i)\n",
    "        segment_pixel_num_list.append(num_pixels)\n",
    "        total_pixels += num_pixels\n",
    "    \n",
    "    \n",
    "    information_for_each_segment = []\n",
    "    for i in (list_unique_regions):\n",
    "        image_list = []\n",
    "        image_list.append(i)\n",
    "        image_list.append(segment_pixel_num_list[i-1])\n",
    "        image_list.append(total_pixels)\n",
    "        information_for_each_segment.append(image_list)\n",
    "\n",
    "    return(information_for_each_segment, segments_slic, num_segments)\n",
    "\n",
    "def segmentation_info_felzenszwalb(image, scale, sigma, min_size):\n",
    "    img_np = image.detach().cpu().squeeze().numpy()\n",
    "    segments_felz = felzenszwalb(img_np, scale=scale, sigma=sigma, min_size=min_size)\n",
    "    num_segments = len(np.unique(segments_slic))\n",
    "    list_unique_regions = np.unique(segments_slic)\n",
    "    segment_pixel_num_list = []\n",
    "    total_pixels = 0\n",
    "    for i in (list_unique_regions):\n",
    "        num_pixels = np.count_nonzero(segments_slic == i)\n",
    "        segment_pixel_num_list.append(num_pixels)\n",
    "        total_pixels += num_pixels\n",
    "    \n",
    "    \n",
    "    information_for_each_segment = []\n",
    "    for i in (list_unique_regions):\n",
    "        image_list = []\n",
    "        image_list.append(i)\n",
    "        image_list.append(segment_pixel_num_list[i-1])\n",
    "        image_list.append(total_pixels)\n",
    "        information_for_each_segment.append(image_list)\n",
    "\n",
    "    return(information_for_each_segment, segments_slic, num_segments)\n",
    "\n",
    "\n",
    "\n",
    "def softmax_score(num_total_pixels, num_obf_pixels, model, image, SMU_class_index):\n",
    "    #image = good_img_transform(image)\n",
    "    image = image\n",
    "    logits = model(image).cpu()\n",
    "    #print(logits)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    probs = probs.detach().cpu()\n",
    "    probs = probs.tolist()[0]\n",
    "    probs = probs[SMU_class_index]\n",
    "\n",
    "    return probs\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "\n",
    "def region_explainability(image, top_n_start, model, SMU_class_index, threshold, top_n_stop):\n",
    "    # Get attribution map\n",
    "    explainability_mask = get_grayscale_grad_cam(image,SMU_class_index)\n",
    "    # Get segment mask\n",
    "    seg = segmentation_info_slic(image = image, num_segments = 25, compactness = 1)\n",
    "    # Calculate average attribution in each superpixel\n",
    "    avg_attr_scores = cam_processor_for_segments(grayscale_cam_output = explainability_mask, segments_slic = seg[1])\n",
    "    # Sort the regions by average attribution, make num_top_attr = the number of segments in the image\n",
    "    top_attrs = attribution_ranker(cam_processor_for_segments_output = avg_attr_scores, num_top_attr = seg[2])\n",
    "    features_1 = get_feature_masks(image = image, attributions = top_attrs, segments_slic = seg[1])\n",
    "    # features_1 gives us a sorted list of feature masks. Element at position 0 is the top attribution region mask\n",
    "\n",
    "    top_n = top_n_start\n",
    "    score = 1000\n",
    "    prob = 1\n",
    "    \n",
    "    # The computational cost of this loop could be reduced by approximately half\n",
    "    # Currently I do a counterfactual analysis on top_n regions and expand top_n to top_n + 1\n",
    "    # This implementation has us redo the counterfactual analysis of the top_n when doing counterfactual analysis on top_n + 1\n",
    "    \n",
    "    sm1 = softmax(model(image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "    sm_idx1 = np.argmax(sm1)\n",
    "    pred_class = sm1[sm_idx1]\n",
    "    pred = pred_class\n",
    "    \n",
    "    best_score_other_class = 0\n",
    "    \n",
    "    previous_features = False\n",
    "    powerset_list = list()\n",
    "    start = perf_counter()\n",
    "    while pred == pred_class:\n",
    "    #while prob > 0.5:\n",
    "        #image_versions holds the image with regions obfuscated\n",
    "        image_versions = []\n",
    "        #num_pixels_changed holds the count of the number of pixels that are obfuscated\n",
    "        num_pixels_changed = []\n",
    "        #total_attr_list I think gives us the label of the regions that are being obfuscated\n",
    "        total_attr_list = []\n",
    "        #scores holds the score given to the image with regions obfuscated\n",
    "        scores = []\n",
    "        \n",
    "        # features_list contains the features to be analyzed in counterfactual analysis\n",
    "        # features_list will start with the top 1 region and then go on to top 2 and so on\n",
    "        features_list = features_1[0:top_n]\n",
    "\n",
    "\n",
    "        powerset_list = list(more_itertools.powerset(features_list))\n",
    "        # print(type(features_list[-1]))\n",
    "        if previous_features:\n",
    "            powerset_list = np.array([list(ele) for ele in powerset_list if len(ele) != 0], dtype=object)\n",
    "            for ele in powerset_list:\n",
    "                for i, mask in enumerate(ele[:]):\n",
    "                    if np.array_equal(mask, features_list[-1]):\n",
    "                        ele = np.delete(mask, i, axis=0)\n",
    "        else:\n",
    "            powerset_list = [list(ele) for ele in powerset_list if len(ele) != 0]\n",
    "        \n",
    "        \n",
    "        # print(len(powerset_list))\n",
    "        \n",
    "        num_versions = len(powerset_list)\n",
    "        \n",
    "    \n",
    "        #print(image.shape)\n",
    "        \n",
    "        original_image = invTrans(image)\n",
    "        \n",
    "        #print(original_image.shape)\n",
    "        \n",
    "        # image_versions.append(original_image)\n",
    "        # num_pixels_changed.append(0)\n",
    "        # total_attr_list.append(np.zeros((28, 28)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for version in range(num_versions - 1):\n",
    "            obfuscated_image = image\n",
    "            total_attribution = np.zeros((28, 28))\n",
    "            total_num_pixels = total_attribution.size\n",
    "            for mask in range(len(powerset_list[version + 1])):\n",
    "                total_attribution += powerset_list[version + 1][mask]\n",
    "            num_changes = np.count_nonzero(total_attribution)\n",
    "            obfuscated_image = blur_image_from_attribution(image = obfuscated_image,\n",
    "                                                       attribution_map = total_attribution)\n",
    "            obfuscated_image = obfuscated_image.to(device)\n",
    "            #obfuscated_image = invTrans(obfuscated_image)\n",
    "        \n",
    "            # calculate softmax score of obfuscated image on the unsafe image class\n",
    "            # score = softmax_score(num_total_pixels = total_num_pixels,\n",
    "            #                       num_obf_pixels = num_pixels_changed,\n",
    "            #                       model = model,\n",
    "            #                       image = obfuscated_image,\n",
    "            #                       SMU_class_index = SMU_class_index)\n",
    "            #print(score)\n",
    "            \n",
    "            # if softmax score is less than 0.5, we want to save it as a counterfactual example\n",
    "            # sm1 is softmax scores of original image, sm_idx1 is the index of top softmax score (the predicted class)\n",
    "            # sm1[sm_idx1] gives the softmax score of the predicted class\n",
    "            # sm2 is like sm1 but on an obfuscated image\n",
    "            # sm1 = softmax(model(image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "            # sm_idx1 = np.argmax(sm1)\n",
    "            sm2 = softmax(model(obfuscated_image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "            sm_idx2 = np.argmax(sm2)\n",
    "            \n",
    "            if (sm_idx1 != sm_idx2) and sm2[sm_idx2] > best_score_other_class:\n",
    "                best_score_other_class = sm2[sm_idx2] \n",
    "            \n",
    "            if (sm_idx1 != sm_idx2) and (sm2[sm_idx2] > threshold):\n",
    "                pred_class = sm_idx2\n",
    "                image_versions.append(obfuscated_image)\n",
    "                #sm2[sm_idx1] is the softmax score of the obfuscated image of the original class.\n",
    "                #This score shows us how far the prediction has changed from the original image\n",
    "                scores.append(sm2[sm_idx1])\n",
    "                num_pixels_changed.append(num_changes)\n",
    "                total_attr_list.append(total_attribution)\n",
    "            \n",
    "#             if score < 0.5:\n",
    "#                 prob = score\n",
    "#                 image_versions.append(obfuscated_image)\n",
    "#                 scores.append(score)\n",
    "#                 num_pixels_changed.append(num_changes)\n",
    "#                 total_attr_list.append(total_attribution)\n",
    "                \n",
    "#                 #print(score)\n",
    "        \n",
    "        print(\"Regions analyzed\", top_n)\n",
    "        top_n = top_n + 1\n",
    "        if top_n == top_n_stop:\n",
    "            end = perf_counter() - start\n",
    "            print(f'Total Search time: {end:.3f}')\n",
    "            return -1\n",
    "        previous_features = True\n",
    "    \n",
    "    end = perf_counter() - start\n",
    "    print(f'Total Search time: {end:.3f}')\n",
    "    \n",
    "    top_n = top_n - 1\n",
    "    # Creating an array to hold the information with each counterfactual image we generated\n",
    "    # It is possible that we could have just one counterfactual image\n",
    "    unique_image_info = []\n",
    "    for i in range(len(scores)):\n",
    "        image_list = []\n",
    "        image_list.append(image_versions[i])\n",
    "        image_list.append(num_pixels_changed[i])\n",
    "        image_list.append(total_num_pixels)\n",
    "        image_list.append(scores[i])\n",
    "        image_list.append(total_attr_list[i])\n",
    "        image_list.append(top_n)\n",
    "        image_list.append(avg_attr_scores)\n",
    "        unique_image_info.append(image_list)\n",
    "    \n",
    "    \n",
    "    # Rank the different counterfactual images\n",
    "    ranked_images = image_rankings(get_image_versions = unique_image_info)\n",
    "    \n",
    "    # Get the best ranked image\n",
    "    best_masked_image = ranked_images[0]\n",
    "    \n",
    "    return best_masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa1a54de-3080-4618-bef6-62059c120e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9706076430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#images, labels = next(itertools.islice(testloader, 48, None))\n",
    "images, labels = next(itertools.islice(test_data, 26, None))\n",
    "\n",
    "print(labels)\n",
    "outputs = model(images.to(device))\n",
    "_, predicted = outputs.max(1)\n",
    "print(predicted)\n",
    "pred_val = predicted.item()\n",
    "plt.imshow( images.detach().cpu().squeeze(), cmap='gray' )\n",
    "\n",
    "# Good sevens: 0, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68775b9-cda0-47e9-ae96-cb31617d6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 17\n",
      "index: 26\n",
      "index: 34\n",
      "index: 36\n",
      "index: 41\n",
      "index: 60\n",
      "index: 64\n",
      "index: 70\n",
      "index: 75\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "n = 0\n",
    "while i < 10:\n",
    "    torch.manual_seed(0)\n",
    "    #testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    #images, labels = next(itertools.islice(testloader, n, None))\n",
    "    images, labels = next(itertools.islice(test_data, n, None))\n",
    "    just_label = labels.item()\n",
    "    \n",
    "    outputs = model(images.to(device))\n",
    "    _, predicted = outputs.max(1)\n",
    "    predicted = predicted.cpu().item()\n",
    "    \n",
    "    if just_label == 7 and predicted == 7:\n",
    "        print('index:', n)\n",
    "        i += 1\n",
    "    \n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b73904f2-f297-44c2-b772-95921e51ed3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9705fe37f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inv_img = images\n",
    "img_np = inv_img.detach().cpu().squeeze().numpy()\n",
    "#plt.imshow(img_np)\n",
    "# compactness=50\n",
    "segments_slic = slic(img_np, n_segments=25, compactness=1,\n",
    "                     start_label=1)\n",
    "plt.imshow(segmentation.mark_boundaries(img_np, segments_slic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec91c4a-f5a8-47df-880e-fa8ef3e2f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_example = region_explainability(image = images, top_n_start = 1, model = model, SMU_class_index = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "079ce5a4-26e3-4d45-ac78-d2b727281400",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'working_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13967/3530658002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_example\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'working_example' is not defined"
     ]
    }
   ],
   "source": [
    "print(working_example[-2])\n",
    "print(working_example[-1])\n",
    "print(model(images.to(device)))\n",
    "print(model(working_example[0].to(device)))\n",
    "plt.imshow(working_example[0].detach().cpu().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39d1964c-c910-479b-89f9-dc56a3a40c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7])\n",
      "tensor([7], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96f5a34370>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#images, labels = next(itertools.islice(testloader, 48, None))\n",
    "images, labels = next(itertools.islice(test_data, 60, None))\n",
    "\n",
    "print(labels)\n",
    "outputs = model(images.to(device))\n",
    "_, predicted = outputs.max(1)\n",
    "print(predicted)\n",
    "pred_val = predicted.item()\n",
    "plt.imshow( images.detach().cpu().squeeze(), cmap='gray' )\n",
    "\n",
    "# Good sevens:index: 0, 17, 26, 34, 36, 41, 60, 64, 70, 75\n",
    "# Good outputs 17, 48, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc66067e-f097-45ba-9716-46abc5f87595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96f1b627f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "print(grayscale_cam.min())\n",
    "plt.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3520a887-77ae-4f06-8ebd-ac19679750f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: target_layers is ignored in FullGrad. All bias layers will be used instead\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f970507f7c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = FullGrad(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "print(grayscale_cam.min())\n",
    "plt.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6a07dec-585e-4b4c-8e4e-99668cd3480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96f19a2970>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = GradCAMPlusPlus(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "print(grayscale_cam.min())\n",
    "plt.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75a41d2d-6991-494e-a118-87059f41679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96f57c7d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = XGradCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "print(grayscale_cam.min())\n",
    "plt.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa9fb88e-f242-4a43-a5ef-76c65d43c3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: You are using ScoreCAM with target layers, however ScoreCAM will ignore them.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13967/2586869667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtarget_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScoreCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgrayscale_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgrayscale_cam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrayscale_cam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrayscale_cam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_grad_cam/base_cam.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_tensor, targets, aug_smooth, eigen_smooth)\u001b[0m\n\u001b[1;32m    182\u001b[0m                 input_tensor, targets, eigen_smooth)\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         return self.forward(input_tensor,\n\u001b[0m\u001b[1;32m    185\u001b[0m                             targets, eigen_smooth)\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_grad_cam/base_cam.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# use all conv layers for example, all Batchnorm layers,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# or something else.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         cam_per_layer = self.compute_cam_per_layer(input_tensor,\n\u001b[0m\u001b[1;32m     94\u001b[0m                                                    \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                                                    eigen_smooth)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_grad_cam/base_cam.py\u001b[0m in \u001b[0;36mcompute_cam_per_layer\u001b[0;34m(self, input_tensor, targets, eigen_smooth)\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0mlayer_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             cam = self.get_cam_image(input_tensor,\n\u001b[0m\u001b[1;32m    126\u001b[0m                                      \u001b[0mtarget_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                                      \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_grad_cam/base_cam.py\u001b[0m in \u001b[0;36mget_cam_image\u001b[0;34m(self, input_tensor, target_layer, targets, activations, grads, eigen_smooth)\u001b[0m\n\u001b[1;32m     48\u001b[0m                       eigen_smooth: bool = False) -> np.ndarray:\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         weights = self.get_cam_weights(input_tensor,\n\u001b[0m\u001b[1;32m     51\u001b[0m                                        \u001b[0mtarget_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                                        \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_grad_cam/score_cam.py\u001b[0m in \u001b[0;36mget_cam_weights\u001b[0;34m(self, input_tensor, target_layer, targets, activations, grads)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mupsampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mupsampled\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxs\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             input_tensors = input_tensor[:, None,\n\u001b[0m\u001b[1;32m     47\u001b[0m                                          :, :] * upsampled[:, :, None, :, :]\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = ScoreCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "print(grayscale_cam.min())\n",
    "plt.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79a2508-c955-4c57-8d5e-2be0f67c98aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions analyzed 1\n",
      "Regions analyzed 2\n",
      "Regions analyzed 3\n",
      "Regions analyzed 4\n",
      "Regions analyzed 5\n",
      "Regions analyzed 6\n",
      "Regions analyzed 7\n",
      "Regions analyzed 8\n",
      "Regions analyzed 9\n",
      "Regions analyzed 10\n",
      "Regions analyzed 11\n",
      "Regions analyzed 12\n",
      "Regions analyzed 13\n",
      "Regions analyzed 14\n",
      "Regions analyzed 15\n",
      "Regions analyzed 16\n",
      "Regions analyzed 17\n",
      "Regions analyzed 18\n",
      "Regions analyzed 19\n",
      "Total Search time: 742.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regions analyzed 19\n",
      "Original Version Predicted Class: 7    With Confidence: 0.9999999\n",
      "Modified Version Predicted Class: 1    With Confidence: 0.92319435\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96f50fce50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Just give an images and it will output\n",
    "\n",
    "input_tensor = images.to(device)\n",
    "targets = [ClassifierOutputTarget(7)]\n",
    "target_layers = [model.layer2]\n",
    "cam = GradCAM(model=model, target_layers=target_layers)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=targets)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "inv_img = images\n",
    "img_np = inv_img.detach().cpu().squeeze().numpy()\n",
    "#plt.imshow(img_np)\n",
    "# compactness=50\n",
    "segments_slic = slic(img_np, n_segments=25, compactness=1,\n",
    "                     start_label=1)\n",
    "\n",
    "working_example = region_explainability(image = images, top_n_start = 1, \n",
    "                                        model = model, SMU_class_index = 7, \n",
    "                                        threshold = 0.8, top_n_stop = 21)\n",
    "print(\"regions analyzed\", working_example[-2])\n",
    "sm1 = softmax(model(images.to(device)).cpu().detach().numpy()).squeeze()\n",
    "sm_idx1 = np.argmax(sm1)\n",
    "sm2 = softmax(model(working_example[0].to(device)).cpu().detach().numpy()).squeeze()\n",
    "sm_idx2 = np.argmax(sm2)\n",
    "print(\"Original Version Predicted Class:\",sm_idx1, \"   With Confidence:\", sm1[sm_idx1])\n",
    "print(\"Modified Version Predicted Class:\",sm_idx2, \"   With Confidence:\", sm2[sm_idx2])\n",
    "#print(sm2)\n",
    "\n",
    "#print(model(images.to(device)))\n",
    "#print(model(working_example[0].to(device)))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4)\n",
    "ax1.imshow(images.detach().cpu().squeeze(), cmap='gray' )\n",
    "ax2.imshow(grayscale_cam, cmap='gray', vmin=0, vmax=1)\n",
    "ax3.imshow(segmentation.mark_boundaries(img_np, segments_slic))\n",
    "ax4.imshow(working_example[0].detach().cpu().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f886cda-92c8-481a-82f5-e09414e6c08e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "964de447-2c49-4819-9783-95943389ecac",
   "metadata": {},
   "source": [
    "# Quantitative Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb30cc76-24d6-4a87-808a-12501799d81a",
   "metadata": {},
   "source": [
    "## Experimenting with different clustering methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c737dd-66be-48ea-8bfc-2f3ff778abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To test our algorithm with SLIC with 25 regions and 1 compactness\n",
    "def region_explainability(image, top_n_start, model, SMU_class_index):\n",
    "    # Get attribution map\n",
    "    explainability_mask = get_grayscale_grad_cam(image,SMU_class_index)\n",
    "    # Get segment mask\n",
    "    seg = segmentation_info_slic(image = image, num_segments = 25, compactness = 1)\n",
    "    # Calculate average attribution in each superpixel\n",
    "    avg_attr_scores = cam_processor_for_segments(grayscale_cam_output = explainability_mask, segments_slic = seg[1])\n",
    "    # Sort the regions by average attribution, make num_top_attr = the number of segments in the image\n",
    "    top_attrs = attribution_ranker(cam_processor_for_segments_output = avg_attr_scores, num_top_attr = seg[2])\n",
    "    features_1 = get_feature_masks(image = image, attributions = top_attrs, segments_slic = seg[1])\n",
    "    # features_1 gives us a sorted list of feature masks. Element at position 0 is the top attribution region mask\n",
    "\n",
    "    top_n = top_n_start\n",
    "    score = 1000\n",
    "    prob = 1\n",
    "    \n",
    "    # The computational cost of this loop could be reduced by approximately half\n",
    "    # Currently I do a counterfactual analysis on top_n regions and expand top_n to top_n + 1\n",
    "    # This implementation has us redo the counterfactual analysis of the top_n when doing counterfactual analysis on top_n + 1\n",
    "    \n",
    "    sm1 = softmax(model(image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "    sm_idx1 = np.argmax(sm1)\n",
    "    pred_class = sm1[sm_idx1]\n",
    "    pred = pred_class\n",
    "    \n",
    "    while pred == pred_class:\n",
    "    #while prob > 0.5:\n",
    "        #image_versions holds the image with regions obfuscated\n",
    "        image_versions = []\n",
    "        #num_pixels_changed holds the count of the number of pixels that are obfuscated\n",
    "        num_pixels_changed = []\n",
    "        #total_attr_list I think gives us the label of the regions that are being obfuscated\n",
    "        total_attr_list = []\n",
    "        #scores holds the score given to the image with regions obfuscated\n",
    "        scores = []\n",
    "        \n",
    "        # features_list contains the features to be analyzed in counterfactual analysis\n",
    "        # features_list will start with the top 1 region and then go on to top 2 and so on\n",
    "        features_list = features_1[0:top_n]\n",
    "        \n",
    "        powerset_list = list(more_itertools.powerset(features_list))\n",
    "        powerset_list = [list(ele) for ele in powerset_list]\n",
    "        num_versions = len(powerset_list)\n",
    "        \n",
    "        #print(image.shape)\n",
    "        \n",
    "        original_image = invTrans(image)\n",
    "        \n",
    "        #print(original_image.shape)\n",
    "        \n",
    "        # image_versions.append(original_image)\n",
    "        # num_pixels_changed.append(0)\n",
    "        # total_attr_list.append(np.zeros((28, 28)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for version in range(num_versions - 1):\n",
    "            obfuscated_image = image\n",
    "            total_attribution = np.zeros((28, 28))\n",
    "            total_num_pixels = total_attribution.size\n",
    "            for mask in range(len(powerset_list[version + 1])):\n",
    "                total_attribution += powerset_list[version + 1][mask]\n",
    "            num_changes = np.count_nonzero(total_attribution)\n",
    "            obfuscated_image = blur_image_from_attribution(image = obfuscated_image,\n",
    "                                                       attribution_map = total_attribution)\n",
    "            obfuscated_image = obfuscated_image.to(device)\n",
    "            #obfuscated_image = invTrans(obfuscated_image)\n",
    "        \n",
    "            # calculate softmax score of obfuscated image on the unsafe image class\n",
    "            # score = softmax_score(num_total_pixels = total_num_pixels,\n",
    "            #                       num_obf_pixels = num_pixels_changed,\n",
    "            #                       model = model,\n",
    "            #                       image = obfuscated_image,\n",
    "            #                       SMU_class_index = SMU_class_index)\n",
    "            #print(score)\n",
    "            \n",
    "            # if softmax score is less than 0.5, we want to save it as a counterfactual example\n",
    "            # sm1 is softmax scores of original image, sm_idx1 is the index of top softmax score (the predicted class)\n",
    "            # sm1[sm_idx1] gives the softmax score of the predicted class\n",
    "            # sm2 is like sm1 but on an obfuscated image\n",
    "            # sm1 = softmax(model(image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "            # sm_idx1 = np.argmax(sm1)\n",
    "            sm2 = softmax(model(obfuscated_image.to(device)).cpu().detach().numpy()).squeeze()\n",
    "            sm_idx2 = np.argmax(sm2)\n",
    "            if sm_idx1 != sm_idx2:\n",
    "                pred_class = sm_idx2\n",
    "                image_versions.append(obfuscated_image)\n",
    "                #sm2[sm_idx1] is the softmax score of the obfuscated image of the original class.\n",
    "                #This score shows us how far the prediction has changed from the original image\n",
    "                scores.append(sm2[sm_idx1])\n",
    "                num_pixels_changed.append(num_changes)\n",
    "                total_attr_list.append(total_attribution)\n",
    "            \n",
    "#             if score < 0.5:\n",
    "#                 prob = score\n",
    "#                 image_versions.append(obfuscated_image)\n",
    "#                 scores.append(score)\n",
    "#                 num_pixels_changed.append(num_changes)\n",
    "#                 total_attr_list.append(total_attribution)\n",
    "                \n",
    "#                 #print(score)\n",
    "        \n",
    "        print(\"Regions analyzed\", top_n)\n",
    "        top_n = top_n + 1\n",
    "    \n",
    "    top_n = top_n - 1\n",
    "    # Creating an array to hold the information with each counterfactual image we generated\n",
    "    # It is possible that we could have just one counterfactual image\n",
    "    unique_image_info = []\n",
    "    for i in range(len(scores)):\n",
    "        image_list = []\n",
    "        image_list.append(image_versions[i])\n",
    "        image_list.append(num_pixels_changed[i])\n",
    "        image_list.append(total_num_pixels)\n",
    "        image_list.append(scores[i])\n",
    "        image_list.append(total_attr_list[i])\n",
    "        image_list.append(top_n)\n",
    "        image_list.append(avg_attr_scores)\n",
    "        unique_image_info.append(image_list)\n",
    "    \n",
    "    \n",
    "    # Rank the different counterfactual images\n",
    "    ranked_images = image_rankings(get_image_versions = unique_image_info)\n",
    "    \n",
    "    # Get the best ranked image\n",
    "    best_masked_image = ranked_images[0]\n",
    "    \n",
    "    return best_masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92ea514-1555-436c-aa39-76858a9cf280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To test our algorithm with SLIC with 25 regions and 1 compactness\n",
    "i = 0\n",
    "n = 0\n",
    "image_info_list = []\n",
    "while i < 50:\n",
    "    torch.manual_seed(0)\n",
    "    #testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True, num_workers=2)\n",
    "    #images, labels = next(itertools.islice(testloader, n, None))\n",
    "    images, labels = next(itertools.islice(test_data, n, None))\n",
    "    just_label = labels.item()\n",
    "    \n",
    "    outputs = model(images.to(device))\n",
    "    _, predicted = outputs.max(1)\n",
    "    predicted = predicted.cpu().item()\n",
    "    #n += 1\n",
    "    #print()\n",
    "    #print(predicted)\n",
    "    \n",
    "    logits = model(images.to(device)).cpu()\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    probs = probs.detach().cpu()\n",
    "    probs = probs.tolist()[0]\n",
    "    # Change probs[int] to int = SMU class index\n",
    "    probs_orig = probs[0]\n",
    "    #print(probs)\n",
    "    \n",
    "    \n",
    "    if just_label == 7 and predicted ==7:\n",
    "        print('index:', i+1)\n",
    "        i += 1\n",
    "        \n",
    "        re = region_explainability(image = images, top_n_start = 1, model = model, SMU_class_index = 7)\n",
    "        \n",
    "        \n",
    "        image_info = []\n",
    "        example = re[0]\n",
    "        exam_img = good_img_transform(example)\n",
    "        logits = model(exam_img).cpu()\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        probs = probs.detach().cpu()\n",
    "        probs = probs.tolist()[0]\n",
    "        # Change probs[int] to int = SMU class index\n",
    "        probs_obf = probs[0]\n",
    "        #print(probs)\n",
    "        image_info.append(probs_orig)\n",
    "        image_info.append(probs_obf)\n",
    "        \n",
    "        num_pixels_obf = re[1]\n",
    "        image_info.append(num_pixels_obf)\n",
    "        image_info.append(re[5])\n",
    "        sm1 = softmax(model(example.to(device)).cpu().detach().numpy()).squeeze()\n",
    "        sm_idx1 = np.argmax(sm1)\n",
    "        #sm_idx1 is the predicted class of the obfuscated image\n",
    "        image_info.append(sm_idx1)\n",
    "        \n",
    "        image_info_list.append(image_info)\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b12456-0462-4376-ba6c-ce7a3fd69479",
   "metadata": {},
   "outputs": [],
   "source": [
    "success = 0\n",
    "total = len(image_info_list)\n",
    "total_pix = total * 28 * 28\n",
    "total_obf = 0\n",
    "total_orig_conf = 0\n",
    "total_obf_conf = 0\n",
    "total_regions = 0\n",
    "preds_on_images = []\n",
    "for i in range(len(image_info_list)):\n",
    "    total_orig_conf += image_info_list[i][0]\n",
    "    total_obf_conf += image_info_list[i][1]\n",
    "    total_obf += image_info_list[i][2]\n",
    "    total_regions += image_info_list[i][3]\n",
    "    preds_on_images.append(image_info_list[i][4])\n",
    "\n",
    "\n",
    "array_np = np.array(preds_on_images)\n",
    "unique, counts = np.unique(array_np, return_counts=True)\n",
    "#print(dict(zip(unique, counts)))\n",
    "\n",
    "print(\"Experiment with SLIC with 25 segments and 1 compactness\")\n",
    "print(\"Average number of regions analyzed: \", total_regions / total)\n",
    "print(\"Average confidence change: \", ((total_orig_conf - total_obf_conf) / total) )\n",
    "print(\"Distribution of changed to class: \", dict(zip(unique, counts)))\n",
    "print(\"Average obfuscation: \",total_obf / total_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf22ea-15a9-4b6d-96b4-a2633eec562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To test our algorithm with felz with 25 regions and 1 compactness\n",
    "def region_explainability(image, top_n_start, model, SMU_class_index):\n",
    "    # Get attribution map\n",
    "    explainability_mask = get_grayscale_grad_cam(image,SMU_class_index)\n",
    "    # Get segment mask\n",
    "    seg = segmentation_info_slic(image = image, num_segments = 25, compactness = 1)\n",
    "    # Calculate average attribution in each superpixel\n",
    "    avg_attr_scores = cam_processor_for_segments(grayscale_cam_output = explainability_mask, segments_slic = seg[1])\n",
    "    # Sort the regions by average attribution, make num_top_attr = the number of segments in the image\n",
    "    top_attrs = attribution_ranker(cam_processor_for_segments_output = avg_attr_scores, num_top_attr = seg[2])\n",
    "    features_1 = get_feature_masks(image = image, attributions = top_attrs, segments_slic = seg[1])\n",
    "    # features_1 gives us a sorted list of feature masks. Element at position 0 is the top attribution region mask\n",
    "\n",
    "    top_n = top_n_start\n",
    "    score = 1000\n",
    "    prob = 1\n",
    "    \n",
    "    # The computational cost of this loop could be reduced by approximately half\n",
    "    # Currently I do a counterfactual analysis on top_n regions and expand top_n to top_n + 1\n",
    "    # This implementation has us redo the counterfactual analysis of the top_n when doing counterfactual analysis on top_n + 1\n",
    "\n",
    "    while prob > 0.5:\n",
    "        #image_versions holds the image with regions obfuscated\n",
    "        image_versions = []\n",
    "        #num_pixels_changed holds the count of the number of pixels that are obfuscated\n",
    "        num_pixels_changed = []\n",
    "        #total_attr_list I think gives us the label of the regions that are being obfuscated\n",
    "        total_attr_list = []\n",
    "        #scores holds the score given to the image with regions obfuscated\n",
    "        scores = []\n",
    "        \n",
    "        # features_list contains the features to be analyzed in counterfactual analysis\n",
    "        # features_list will start with the top 1 region and then go on to top 2 and so on\n",
    "        features_list = features_1[0:top_n]\n",
    "        \n",
    "        powerset_list = list(more_itertools.powerset(features_list))\n",
    "        powerset_list = [list(ele) for ele in powerset_list]\n",
    "        num_versions = len(powerset_list)\n",
    "        \n",
    "        #print(image.shape)\n",
    "        \n",
    "        original_image = invTrans(image)\n",
    "        \n",
    "        #print(original_image.shape)\n",
    "        \n",
    "        # image_versions.append(original_image)\n",
    "        # num_pixels_changed.append(0)\n",
    "        # total_attr_list.append(np.zeros((28, 28)))\n",
    "        \n",
    "        \n",
    "        \n",
    "        for version in range(num_versions - 1):\n",
    "            obfuscated_image = image\n",
    "            total_attribution = np.zeros((28, 28))\n",
    "            total_num_pixels = total_attribution.size\n",
    "            for mask in range(len(powerset_list[version + 1])):\n",
    "                total_attribution += powerset_list[version + 1][mask]\n",
    "            num_changes = np.count_nonzero(total_attribution)\n",
    "            obfuscated_image = blur_image_from_attribution(image = obfuscated_image,\n",
    "                                                       attribution_map = total_attribution)\n",
    "            obfuscated_image = obfuscated_image.to(device)\n",
    "            #obfuscated_image = invTrans(obfuscated_image)\n",
    "        \n",
    "            # calculate softmax score of obfuscated image on the unsafe image class\n",
    "            score = softmax_score(num_total_pixels = total_num_pixels,\n",
    "                                  num_obf_pixels = num_pixels_changed,\n",
    "                                  model = model,\n",
    "                                  image = obfuscated_image,\n",
    "                                  SMU_class_index = SMU_class_index)\n",
    "            #print(score)\n",
    "            \n",
    "            # if softmax score is less than 0.5, we want to save it as a counterfactual example\n",
    "            if score < 0.5:\n",
    "                prob = score\n",
    "                image_versions.append(obfuscated_image)\n",
    "                scores.append(score)\n",
    "                num_pixels_changed.append(num_changes)\n",
    "                total_attr_list.append(total_attribution)\n",
    "                \n",
    "                #print(score)\n",
    "        \n",
    "        print(\"Regions analyzed\", top_n)\n",
    "        top_n = top_n + 1\n",
    "    \n",
    "    \n",
    "    # Creating an array to hold the information with each counterfactual image we generated\n",
    "    # It is possible that we could have just one counterfactual image\n",
    "    unique_image_info = []\n",
    "    for i in range(len(scores)):\n",
    "        image_list = []\n",
    "        image_list.append(image_versions[i])\n",
    "        image_list.append(num_pixels_changed[i])\n",
    "        image_list.append(total_num_pixels)\n",
    "        image_list.append(scores[i])\n",
    "        image_list.append(total_attr_list[i])\n",
    "        image_list.append(top_n)\n",
    "        unique_image_info.append(image_list)\n",
    "    \n",
    "    \n",
    "    # Rank the different counterfactual images\n",
    "    ranked_images = image_rankings(get_image_versions = unique_image_info)\n",
    "    \n",
    "    # Get the best ranked image\n",
    "    best_masked_image = ranked_images[0]\n",
    "    \n",
    "    return best_masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db9528-ab90-4a3c-b634-f49274165c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
