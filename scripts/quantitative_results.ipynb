{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc6dac9-d86e-4f9e-ae56-c2c8b48582d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "\n",
    "\n",
    "labelme_dir_path = '/workspace/adv_robustness/region_explainability/labelme'\n",
    "\n",
    "dataset_dir_map = {\n",
    "    0: 'MNIST_71',\n",
    "    1: 'MNIST_94',\n",
    "    2: 'MNIST_pullover_shirt',\n",
    "    3: 'MNIST_sneaker_sandal',\n",
    "    # 4: 'MNIST_sneaker_sandal_75',\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3625ed9e-c6cb-4a03-a0a2-303f41866cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Experimental Results for Dataset: MNIST_71:\n",
      "####################################################################################################\n",
      "\n",
      "\t\tResults for slic_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.85\n",
      "                    avg depth: 11.352941176470589\n",
      " avg proportion pixels masked: 0.17120348139255698\n",
      "\n",
      "\n",
      "\t\tResults for bass_fullgrad:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.98\n",
      "                    avg depth: 6.173469387755102\n",
      " avg proportion pixels masked: 0.22117086630570607\n",
      "\n",
      "\n",
      "\t\tResults for bass_ablation:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.97\n",
      "                    avg depth: 6.814432989690721\n",
      " avg proportion pixels masked: 0.233668209551862\n",
      "\n",
      "\n",
      "\t\tResults for felzen_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.89\n",
      "                    avg depth: 9.48314606741573\n",
      " avg proportion pixels masked: 0.3548068103645953\n",
      "\n",
      "\n",
      "\t\tResults for slic50_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.52\n",
      "                    avg depth: 9.711538461538462\n",
      " avg proportion pixels masked: 0.11619407378335948\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.97\n",
      "                    avg depth: 6.814432989690721\n",
      " avg proportion pixels masked: 0.233668209551862\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcamplusplus:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.97\n",
      "                    avg depth: 6.814432989690721\n",
      " avg proportion pixels masked: 0.233668209551862\n",
      "\n",
      "\n",
      "\t\tResults for watershed_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.68\n",
      "                    avg depth: 15.132352941176471\n",
      " avg proportion pixels masked: 0.2568089735894359\n",
      "\n",
      "\n",
      "\t\tResults for slic40_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.55\n",
      "                    avg depth: 8.945454545454545\n",
      " avg proportion pixels masked: 0.11201298701298701\n",
      "\n",
      "\n",
      "\t\tResults for bass_xgradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.97\n",
      "                    avg depth: 6.814432989690721\n",
      " avg proportion pixels masked: 0.233668209551862\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grab all metric file names\n",
    "\n",
    "dataset_choice = 0\n",
    "dataset_name = dataset_dir_map[dataset_choice]\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "dataset_path = os.path.join(labelme_dir_path, dataset_name)\n",
    "os.chdir(dataset_path)\n",
    "metric_folder_list = glob.glob('metric*')\n",
    "# print(len(metric_folder_list))\n",
    "\n",
    "print(f'All Experimental Results for Dataset: {dataset_name}:')\n",
    "print('#'*100)\n",
    "for result in metric_folder_list:\n",
    "    result_type = result.split('_')[-2:]\n",
    "    result_type = '_'.join(result_type)\n",
    "    os.chdir(result)\n",
    "    metrics_list = sorted([file for file in glob.glob('*') if file[0] != '.'])\n",
    "    \n",
    "    counterfactual_success_proportion = 0\n",
    "    avg_depth = 0\n",
    "    avg_proportion_pixels_masked = 0\n",
    "    \n",
    "    successes = 0\n",
    "    depths_list = []\n",
    "    proportion_pixels_masked_list = []\n",
    "    \n",
    "    if len(metrics_list) >= 100:\n",
    "        print(f'\\n\\t\\tResults for {result_type}:')\n",
    "        print(f'Total number of tested images: {len(metrics_list)}')\n",
    "        \n",
    "        for file_name in metrics_list:\n",
    "        \n",
    "            metric = torch.load(file_name)\n",
    "            if isinstance(metric, list):\n",
    "                successes += 1\n",
    "                depths_list.append(metric[-3])\n",
    "                proportion_pixels_masked_list.append(metric[1] / metric[2])\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        counterfactual_success_proportion = successes / len(metrics_list)\n",
    "        avg_depth = sum(depths_list) / successes\n",
    "        avg_proportion_pixels_masked = sum(proportion_pixels_masked_list) / successes\n",
    "        \n",
    "        print(f'  counterfactual success rate: {counterfactual_success_proportion}')\n",
    "        print(f'                    avg depth: {avg_depth}')\n",
    "        print(f' avg proportion pixels masked: {avg_proportion_pixels_masked}')\n",
    "    \n",
    "        print()\n",
    "    os.chdir(dataset_path)\n",
    "\n",
    "os.chdir(cwd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4339d7f-ac6d-4cf8-ad80-a49ca0b8239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Experimental Results for Dataset: MNIST_94:\n",
      "####################################################################################################\n",
      "\n",
      "\t\tResults for slic_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 2.23\n",
      " avg proportion pixels masked: 0.0706377551020408\n",
      "\n",
      "\n",
      "\t\tResults for bass_fullgrad:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 4.82\n",
      " avg proportion pixels masked: 0.18487244897959187\n",
      "\n",
      "\n",
      "\t\tResults for bass_ablation:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 5.02\n",
      " avg proportion pixels masked: 0.18729591836734694\n",
      "\n",
      "\n",
      "\t\tResults for felzen_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 4.52\n",
      " avg proportion pixels masked: 0.10394132653061222\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 5.02\n",
      " avg proportion pixels masked: 0.18729591836734694\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcamplusplus:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 5.02\n",
      " avg proportion pixels masked: 0.18729591836734694\n",
      "\n",
      "\n",
      "\t\tResults for watershed_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 5.56\n",
      " avg proportion pixels masked: 0.1659948979591836\n",
      "\n",
      "\n",
      "\t\tResults for bass_xgradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 5.02\n",
      " avg proportion pixels masked: 0.18729591836734694\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grab all metric file names\n",
    "\n",
    "dataset_choice = 1\n",
    "dataset_name = dataset_dir_map[dataset_choice]\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "dataset_path = os.path.join(labelme_dir_path, dataset_name)\n",
    "os.chdir(dataset_path)\n",
    "metric_folder_list = glob.glob('metric*')\n",
    "# print(len(metric_folder_list))\n",
    "\n",
    "print(f'All Experimental Results for Dataset: {dataset_name}:')\n",
    "print('#'*100)\n",
    "for result in metric_folder_list:\n",
    "    result_type = result.split('_')[-2:]\n",
    "    result_type = '_'.join(result_type)\n",
    "    os.chdir(result)\n",
    "    metrics_list = sorted([file for file in glob.glob('*') if file[0] != '.'])\n",
    "    \n",
    "    counterfactual_success_proportion = 0\n",
    "    avg_depth = 0\n",
    "    avg_proportion_pixels_masked = 0\n",
    "    \n",
    "    successes = 0\n",
    "    depths_list = []\n",
    "    proportion_pixels_masked_list = []\n",
    "    \n",
    "    if len(metrics_list) >= 100:\n",
    "        print(f'\\n\\t\\tResults for {result_type}:')\n",
    "        print(f'Total number of tested images: {len(metrics_list)}')\n",
    "        \n",
    "        for file_name in metrics_list:\n",
    "        \n",
    "            metric = torch.load(file_name)\n",
    "            if isinstance(metric, list):\n",
    "                successes += 1\n",
    "                depths_list.append(metric[-3])\n",
    "                proportion_pixels_masked_list.append(metric[1] / metric[2])\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        counterfactual_success_proportion = successes / len(metrics_list)\n",
    "        avg_depth = sum(depths_list) / successes\n",
    "        avg_proportion_pixels_masked = sum(proportion_pixels_masked_list) / successes\n",
    "        \n",
    "        print(f'  counterfactual success rate: {counterfactual_success_proportion}')\n",
    "        print(f'                    avg depth: {avg_depth}')\n",
    "        print(f' avg proportion pixels masked: {avg_proportion_pixels_masked}')\n",
    "    \n",
    "        print()\n",
    "    os.chdir(dataset_path)\n",
    "\n",
    "os.chdir(cwd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f89d84a9-531c-4815-b754-fd1675995a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Experimental Results for Dataset: MNIST_pullover_shirt:\n",
      "####################################################################################################\n",
      "\n",
      "\t\tResults for slic_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 9.99\n",
      " avg proportion pixels masked: 0.17635204081632658\n",
      "\n",
      "\n",
      "\t\tResults for bass_fullgrad:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 8.91\n",
      " avg proportion pixels masked: 0.3456887755102042\n",
      "\n",
      "\n",
      "\t\tResults for bass_ablation:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 9.55\n",
      " avg proportion pixels masked: 0.3021301020408163\n",
      "\n",
      "\n",
      "\t\tResults for felzen_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.82\n",
      "                    avg depth: 14.036585365853659\n",
      " avg proportion pixels masked: 0.12728658536585366\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 9.55\n",
      " avg proportion pixels masked: 0.3021301020408163\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcamplusplus:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 9.55\n",
      " avg proportion pixels masked: 0.3021301020408163\n",
      "\n",
      "\n",
      "\t\tResults for watershed_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 8.78\n",
      " avg proportion pixels masked: 0.22721938775510198\n",
      "\n",
      "\n",
      "\t\tResults for bass_xgradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 1.0\n",
      "                    avg depth: 9.55\n",
      " avg proportion pixels masked: 0.3021301020408163\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grab all metric file names\n",
    "\n",
    "dataset_choice = 2\n",
    "dataset_name = dataset_dir_map[dataset_choice]\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "dataset_path = os.path.join(labelme_dir_path, dataset_name)\n",
    "os.chdir(dataset_path)\n",
    "metric_folder_list = glob.glob('metric*')\n",
    "# print(len(metric_folder_list))\n",
    "\n",
    "print(f'All Experimental Results for Dataset: {dataset_name}:')\n",
    "print('#'*100)\n",
    "for result in metric_folder_list:\n",
    "    result_type = result.split('_')[-2:]\n",
    "    result_type = '_'.join(result_type)\n",
    "    os.chdir(result)\n",
    "    metrics_list = sorted([file for file in glob.glob('*') if file[0] != '.'])\n",
    "    \n",
    "    counterfactual_success_proportion = 0\n",
    "    avg_depth = 0\n",
    "    avg_proportion_pixels_masked = 0\n",
    "    \n",
    "    successes = 0\n",
    "    depths_list = []\n",
    "    proportion_pixels_masked_list = []\n",
    "    \n",
    "    if len(metrics_list) >= 100:\n",
    "        print(f'\\n\\t\\tResults for {result_type}:')\n",
    "        print(f'Total number of tested images: {len(metrics_list)}')\n",
    "        \n",
    "        for file_name in metrics_list:\n",
    "        \n",
    "            metric = torch.load(file_name)\n",
    "            if isinstance(metric, list):\n",
    "                successes += 1\n",
    "                depths_list.append(metric[-3])\n",
    "                proportion_pixels_masked_list.append(metric[1] / metric[2])\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        counterfactual_success_proportion = successes / len(metrics_list)\n",
    "        avg_depth = sum(depths_list) / successes\n",
    "        avg_proportion_pixels_masked = sum(proportion_pixels_masked_list) / successes\n",
    "        \n",
    "        print(f'  counterfactual success rate: {counterfactual_success_proportion}')\n",
    "        print(f'                    avg depth: {avg_depth}')\n",
    "        print(f' avg proportion pixels masked: {avg_proportion_pixels_masked}')\n",
    "    \n",
    "        print()\n",
    "    os.chdir(dataset_path)\n",
    "\n",
    "os.chdir(cwd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7fbafba-1512-4954-84e4-a5b1e1ec885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Experimental Results for Dataset: MNIST_sneaker_sandal:\n",
      "####################################################################################################\n",
      "\n",
      "\t\tResults for slic_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.61\n",
      "                    avg depth: 16.147540983606557\n",
      " avg proportion pixels masked: 0.1500083640013383\n",
      "\n",
      "\n",
      "\t\tResults for bass_fullgrad:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.68\n",
      "                    avg depth: 10.705882352941176\n",
      " avg proportion pixels masked: 0.2971751200480192\n",
      "\n",
      "\n",
      "\t\tResults for bass_ablation:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.69\n",
      "                    avg depth: 11.057971014492754\n",
      " avg proportion pixels masked: 0.32701123927832004\n",
      "\n",
      "\n",
      "\t\tResults for felzen_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.91\n",
      "                    avg depth: 15.076923076923077\n",
      " avg proportion pixels masked: 0.22465799506615833\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.69\n",
      "                    avg depth: 11.057971014492754\n",
      " avg proportion pixels masked: 0.32701123927832004\n",
      "\n",
      "\n",
      "\t\tResults for bass_gradcamplusplus:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.69\n",
      "                    avg depth: 11.057971014492754\n",
      " avg proportion pixels masked: 0.32701123927832004\n",
      "\n",
      "\n",
      "\t\tResults for watershed_gradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.87\n",
      "                    avg depth: 14.954022988505747\n",
      " avg proportion pixels masked: 0.24555770584095715\n",
      "\n",
      "\n",
      "\t\tResults for bass_xgradcam:\n",
      "Total number of tested images: 100\n",
      "  counterfactual success rate: 0.69\n",
      "                    avg depth: 11.057971014492754\n",
      " avg proportion pixels masked: 0.32701123927832004\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grab all metric file names\n",
    "\n",
    "dataset_choice = 3\n",
    "dataset_name = dataset_dir_map[dataset_choice]\n",
    "\n",
    "cwd_path = os.getcwd()\n",
    "dataset_path = os.path.join(labelme_dir_path, dataset_name)\n",
    "os.chdir(dataset_path)\n",
    "metric_folder_list = glob.glob('metric*')\n",
    "# print(len(metric_folder_list))\n",
    "\n",
    "print(f'All Experimental Results for Dataset: {dataset_name}:')\n",
    "print('#'*100)\n",
    "for result in metric_folder_list:\n",
    "    result_type = result.split('_')[-2:]\n",
    "    result_type = '_'.join(result_type)\n",
    "    os.chdir(result)\n",
    "    metrics_list = sorted([file for file in glob.glob('*') if file[0] != '.'])\n",
    "    \n",
    "    counterfactual_success_proportion = 0\n",
    "    avg_depth = 0\n",
    "    avg_proportion_pixels_masked = 0\n",
    "    \n",
    "    successes = 0\n",
    "    depths_list = []\n",
    "    proportion_pixels_masked_list = []\n",
    "    \n",
    "    if len(metrics_list) >= 100:\n",
    "        print(f'\\n\\t\\tResults for {result_type}:')\n",
    "        print(f'Total number of tested images: {len(metrics_list)}')\n",
    "        \n",
    "        for file_name in metrics_list:\n",
    "        \n",
    "            metric = torch.load(file_name)\n",
    "            if isinstance(metric, list):\n",
    "                successes += 1\n",
    "                depths_list.append(metric[-3])\n",
    "                proportion_pixels_masked_list.append(metric[1] / metric[2])\n",
    "            else:\n",
    "                pass\n",
    "                \n",
    "        counterfactual_success_proportion = successes / len(metrics_list)\n",
    "        avg_depth = sum(depths_list) / successes\n",
    "        avg_proportion_pixels_masked = sum(proportion_pixels_masked_list) / successes\n",
    "        \n",
    "        print(f'  counterfactual success rate: {counterfactual_success_proportion}')\n",
    "        print(f'                    avg depth: {avg_depth}')\n",
    "        print(f' avg proportion pixels masked: {avg_proportion_pixels_masked}')\n",
    "    \n",
    "        print()\n",
    "    os.chdir(dataset_path)\n",
    "\n",
    "os.chdir(cwd_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd8990-e7eb-41d0-879e-2eb95ba37056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
